{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUuKRCRBpQhGL3c7MZXeZJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_zYNoLp5IXr","executionInfo":{"status":"ok","timestamp":1768099059828,"user_tz":-330,"elapsed":72526,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"5e447062-0893-4f50-f01c-0f3f77705ad5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ML/DL_With_Pytorch\n","remote: Enumerating objects: 5, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Unpacking objects: 100% (3/3), 940 bytes | 1024 bytes/s, done.\n","From https://github.com/barada02/DL_With_Pytorch\n"," * branch            main       -> FETCH_HEAD\n","   2cfe18a..2f17d93  main       -> origin/main\n","Updating 2cfe18a..2f17d93\n","Fast-forward\n"," README.md | 11 \u001b[32m+\u001b[m\u001b[31m----------\u001b[m\n"," 1 file changed, 1 insertion(+), 10 deletions(-)\n","✅ Environment Ready!\n"]}],"source":["# Using Drive as storage and github for version controll.\n","\n","from google.colab import drive, userdata\n","import os\n","\n","# 1. Mount Drive\n","drive.mount('/content/drive')\n","\n","# 2. Setup Paths (Change to your actual repo name)\n","REPO_PATH = \"/content/drive/MyDrive/ML/DL_With_Pytorch\"\n","%cd {REPO_PATH}\n","\n","# 3. Secure Auth\n","token = userdata.get('GH_TOKEN')\n","username = \"barada02\"\n","repo = \"DL_With_Pytorch\"\n","!git remote set-url origin https://{token}@github.com/{username}/{repo}.git\n","\n","# 4. Identity\n","!git config --global user.email \"Chandanbarada2@gmail.com\"\n","!git config --global user.name \"Kumar\"\n","\n","!git pull origin main\n","print(\"✅ Environment Ready!\")"]},{"cell_type":"code","source":["# Push notebook changes to GitHub\n","# IMPORTANT: Press Ctrl+S (Save) before running this!\n","!git add .\n","!git commit -m \"concat\"\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XE9WW_YF6HqA","executionInfo":{"status":"ok","timestamp":1768101639161,"user_tz":-330,"elapsed":2491,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"1d447ad7-a5e9-42f7-bab6-cfb1a4264c1e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 02cc268] concat\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite 01_Tensors_02_operations.ipynb (64%)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 1.81 KiB | 154.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/barada02/DL_With_Pytorch.git\n","   4a4011c..02cc268  main -> main\n"]}]},{"cell_type":"markdown","source":["# Note book starts from here"],"metadata":{"id":"6z2VJMPh6miG"}},{"cell_type":"code","source":["\n","import torch\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_lCavztT6x0b","executionInfo":{"status":"ok","timestamp":1768099461794,"user_tz":-330,"elapsed":3467,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"aacfbed8-8404-4b81-fef1-1f1808e8b939"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.0+cpu\n"]}]},{"cell_type":"markdown","source":["# Tensor operations"],"metadata":{"id":"1T-SSLpx6szV"}},{"cell_type":"markdown","source":["* By default, tensors are created on the CPU. We need to explicitly move tensors to the accelerator using ```.to``` method (after checking for accelerator availability).\n","* Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"],"metadata":{"id":"4GlWLw-17zze"}},{"cell_type":"code","source":["# We move our tensor to the current accelerator if available\n","if torch.accelerator.is_available():\n","    tensor = tensor.to(torch.accelerator.current_accelerator())"],"metadata":{"id":"IN2nLxAk6sM3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Standard numpy-like indexing and slicking:"],"metadata":{"id":"vGMA7GUG8nhV"}},{"cell_type":"code","source":["tensor = torch.ones(3,3)\n","print(tensor)\n","print(tensor.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkhezX998CnR","executionInfo":{"status":"ok","timestamp":1768099683681,"user_tz":-330,"elapsed":212,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"b94291e9-ca48-4cf8-d7e3-8c802bf15d3a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","torch.float32\n"]}]},{"cell_type":"code","source":["print(f\"First row:{tensor[0]}\")\n","print(f\"First coloumn:{tensor[:,0]}\")\n","print(f\"Last coloumn:{tensor[...,-1]}\")\n","tensor[:,1]=0 #slicing and assignment.In-place Operation: This modifies the original tensor. It doesn't create a new one;\n","print(tensor)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXvkjsV_84GR","executionInfo":{"status":"ok","timestamp":1768099789970,"user_tz":-330,"elapsed":248,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"9c4d2ae5-3f82-490a-fcf8-50552c52f3ff"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["First row:tensor([1., 1., 1.])\n","First coloumn:tensor([1., 1., 1.])\n","Last coloumn:tensor([1., 1., 1.])\n","tensor([[1., 0., 1.],\n","        [1., 0., 1.],\n","        [1., 0., 1.]])\n"]}]},{"cell_type":"markdown","source":["## Joining Tensors\n","You can use ```torch.cat``` to concatenate a sequence of tensors along a given dimension. See also ```torch.stack```, another tensor joining operator that is subtly different from ```torch.cat```"],"metadata":{"id":"yHw0-WUW9lmi"}},{"cell_type":"code","source":["import torch\n","\n","# t1 is 2 rows, 3 columns\n","t1 = torch.full((2, 3), 1.0)\n","# t2 is 4 rows, 3 columns\n","t2 = torch.full((4, 3), 2.0)\n","\n","# They match in the second dimension (3), so we can stack them vertically\n","vertical_stack = torch.cat([t1, t2], dim=0)\n","\n","print(f\"Tensor 1 Shape: {t1.shape}\")\n","print(f\"Tensor 2 Shape: {t2.shape}\")\n","print(f\"Result Shape:   {vertical_stack.shape}\")\n","print(\"\\nResulting Tensor:\\n\", vertical_stack)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIcSPV539lHS","executionInfo":{"status":"ok","timestamp":1768102829542,"user_tz":-330,"elapsed":6,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"cd99b1ef-17d2-4266-8b90-73dddc6dbb63"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor 1 Shape: torch.Size([2, 3])\n","Tensor 2 Shape: torch.Size([4, 3])\n","Result Shape:   torch.Size([6, 3])\n","\n","Resulting Tensor:\n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.]])\n"]}]},{"cell_type":"code","source":["t3 = torch.cat([t1,t1,t1],dim=1)\n","print(t3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd6sHRzsDPrk","executionInfo":{"status":"ok","timestamp":1768101326089,"user_tz":-330,"elapsed":231,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"c6e1385d-3d25-4fa3-d13b-46b65eca70da"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.4317, -0.9568, -0.4488, -1.4317, -0.9568, -0.4488, -1.4317, -0.9568,\n","         -0.4488],\n","        [ 0.9543,  0.2966, -0.4342,  0.9543,  0.2966, -0.4342,  0.9543,  0.2966,\n","         -0.4342],\n","        [-0.0089, -0.7056, -0.9768, -0.0089, -0.7056, -0.9768, -0.0089, -0.7056,\n","         -0.9768]])\n"]}]},{"cell_type":"code","source":["t4 = torch.randn(2,2,2)\n","print(t4)\n","t5 = torch.randn(2,2,2)\n","print(t5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boBZAWP5DUa4","executionInfo":{"status":"ok","timestamp":1768101406536,"user_tz":-330,"elapsed":238,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"352b47fe-8c39-4261-81d3-a29938565f63"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-1.0604,  0.7685],\n","         [ 0.8733,  0.4160]],\n","\n","        [[-1.9874,  0.3755],\n","         [ 0.0278,  0.5052]]])\n","tensor([[[ 0.1598, -1.0132],\n","         [-0.1319,  0.2742]],\n","\n","        [[ 0.6721, -0.5150],\n","         [-0.2022, -1.4717]]])\n"]}]},{"cell_type":"code","source":["torch.cat([t4,t5],dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XVZVAxwDnv0","executionInfo":{"status":"ok","timestamp":1768101426290,"user_tz":-330,"elapsed":239,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"71fa6edd-1333-4258-a5f6-1038d5bcce35"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-1.0604,  0.7685],\n","         [ 0.8733,  0.4160]],\n","\n","        [[-1.9874,  0.3755],\n","         [ 0.0278,  0.5052]],\n","\n","        [[ 0.1598, -1.0132],\n","         [-0.1319,  0.2742]],\n","\n","        [[ 0.6721, -0.5150],\n","         [-0.2022, -1.4717]]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["torch.cat([t4,t5],dim=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dGVMK7rDtnd","executionInfo":{"status":"ok","timestamp":1768101447956,"user_tz":-330,"elapsed":202,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"4b691283-24d8-4b12-d224-62445292fea8"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-1.0604,  0.7685],\n","         [ 0.8733,  0.4160],\n","         [ 0.1598, -1.0132],\n","         [-0.1319,  0.2742]],\n","\n","        [[-1.9874,  0.3755],\n","         [ 0.0278,  0.5052],\n","         [ 0.6721, -0.5150],\n","         [-0.2022, -1.4717]]])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["torch.cat([t4,t5],dim=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HadvROQADxc9","executionInfo":{"status":"ok","timestamp":1768101467224,"user_tz":-330,"elapsed":242,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"c61094a8-2af4-4d37-cdcb-673470296a89"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-1.0604,  0.7685,  0.1598, -1.0132],\n","         [ 0.8733,  0.4160, -0.1319,  0.2742]],\n","\n","        [[-1.9874,  0.3755,  0.6721, -0.5150],\n","         [ 0.0278,  0.5052, -0.2022, -1.4717]]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["\n","\n","> Concatenates the given sequence of tensors in tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be a 1-D empty tensor with size (0,).\n","\n",">```torch.cat()``` can be seen as an inverse operation for ```torch.split()``` and ```torch.chunk()```.\n","\n",">```torch.cat()``` can be best understood via examples.\n","\n"],"metadata":{"id":"pk5GsaeXEth6"}},{"cell_type":"code","source":["import torch\n","\n","# t1 is 2 rows, 3 columns\n","t1 = torch.full((2, 3), 1.0)\n","# t2 is 4 rows, 3 columns\n","t2 = torch.full((4, 3), 2.0)\n","\n","# They match in the second dimension (3), so we can stack them vertically\n","vertical_stack = torch.cat([t1, t2], dim=0)\n","\n","print(f\"Tensor 1 Shape: {t1.shape}\")\n","print(f\"Tensor 2 Shape: {t2.shape}\")\n","print(f\"Result Shape:   {vertical_stack.shape}\")\n","print(\"\\nResulting Tensor:\\n\", vertical_stack)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rR4qxXhRD2SM","executionInfo":{"status":"ok","timestamp":1768102678524,"user_tz":-330,"elapsed":47,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"a5c992c1-a203-4fe3-b0ea-445b260c8c7b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor 1 Shape: torch.Size([2, 3])\n","Tensor 2 Shape: torch.Size([4, 3])\n","Result Shape:   torch.Size([6, 3])\n","\n","Resulting Tensor:\n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.]])\n"]}]},{"cell_type":"markdown","source":["## Arithmetic Operations"],"metadata":{"id":"xD4bIigJBTIl"}},{"cell_type":"code","source":["# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n","# ``tensor.T`` returns the transpose of a tensor\n","y1 = tensor @ tensor.T\n","y2 = tensor.matmul(tensor.T)\n","\n","y3 = torch.rand_like(y1)\n","torch.matmul(tensor, tensor.T, out=y3)\n","\n","\n","# This computes the element-wise product. z1, z2, z3 will have the same value\n","z1 = tensor * tensor\n","z2 = tensor.mul(tensor)\n","\n","z3 = torch.rand_like(tensor)\n","torch.mul(tensor, tensor, out=z3)"],"metadata":{"id":"-tNc-0Oq_ifF"},"execution_count":null,"outputs":[]}]}