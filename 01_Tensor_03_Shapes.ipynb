{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDRobDqZhEuP3i15r2L7oh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRieNBiirdhV","executionInfo":{"status":"ok","timestamp":1768413955801,"user_tz":-330,"elapsed":40049,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"c2704cd9-2121-43e3-99f7-b32f7178d853"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ML/DL_With_Pytorch\n","From https://github.com/barada02/DL_With_Pytorch\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n","✅ Environment Ready!\n"]}],"source":["# Using Drive as storage and github for version controll.\n","\n","from google.colab import drive, userdata\n","import os\n","\n","# 1. Mount Drive\n","drive.mount('/content/drive')\n","\n","# 2. Setup Paths (Change to your actual repo name)\n","REPO_PATH = \"/content/drive/MyDrive/ML/DL_With_Pytorch\"\n","%cd {REPO_PATH}\n","\n","# 3. Secure Auth\n","token = userdata.get('GH_TOKEN')\n","username = \"barada02\"\n","repo = \"DL_With_Pytorch\"\n","!git remote set-url origin https://{token}@github.com/{username}/{repo}.git\n","\n","# 4. Identity\n","!git config --global user.email \"Chandanbarada2@gmail.com\"\n","!git config --global user.name \"Kumar\"\n","\n","!git pull origin main\n","print(\"✅ Environment Ready!\")"]},{"cell_type":"code","source":["# Push notebook changes to GitHub\n","# IMPORTANT: Press Ctrl+S (Save) before running this!\n","!git add .\n","!git commit -m \"Reshpae and view funciton doc \"\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUILGGWfrue1","executionInfo":{"status":"ok","timestamp":1768414178349,"user_tz":-330,"elapsed":2465,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"92223bac-7a00-4315-a0bc-2289bd46bd58"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[main c5ab28a] Reshpae and view funciton doc\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 1.17 KiB | 85.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/barada02/DL_With_Pytorch.git\n","   c2027f1..c5ab28a  main -> main\n"]}]},{"cell_type":"markdown","source":["# Tensor Shapes"],"metadata":{"id":"K8Bc8ihwr_XQ"}},{"cell_type":"markdown","source":["Manipulating tensor shapes is the bread and butter of deep learning. In PyTorch, these operations allow you to reorganize data to fit the expected input of different layers (like moving from a Convolutional layer to a Linear one)"],"metadata":{"id":"hp-rNi11r_UC"}},{"cell_type":"markdown","source":["# The flatten\n","### Reshape and view"],"metadata":{"id":"ue7mjZqEscTQ"}},{"cell_type":"markdown","source":["Both change the dimensions of a tensor without changing its data, but they handle memory differently.\n","\n","* view(): The OG method. It is very fast because it creates a \"view\" of the original data without copying it. Requirement: The tensor must be contiguous in memory. If you’ve just transposed a tensor, view() might throw an error.\n","\n","* reshape(): The more robust sibling. It tries to return a view if possible, but if the data isn't contiguous, it will silently copy the data to a new memory block.\n","\n","Pro Tip: Use -1 as a dimension to let PyTorch automatically calculate the size for that slot based on the remaining dimensions."],"metadata":{"id":"2UwCZyUrsiA9"}},{"cell_type":"code","source":["import torch\n","\n","# A batch of 4 images, 3 color channels, 28x28 pixels\n","x = torch.randn(4, 3, 28, 28)\n","print(f\"Original shape: {x.shape}\")\n","\n","# Use -1 to say: \"Keep the batch size (4), but squash everything else\"\n","flattened = x.view(4, -1)\n","print(f\"Flattened shape: {flattened.shape}\") # [4, 2352]"],"metadata":{"id":"Pl5b-fIUsMns"},"execution_count":null,"outputs":[]}]}