{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyY3Wj2UK1cXOZl09mMitW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRieNBiirdhV","executionInfo":{"status":"ok","timestamp":1768413955801,"user_tz":-330,"elapsed":40049,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"c2704cd9-2121-43e3-99f7-b32f7178d853"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ML/DL_With_Pytorch\n","From https://github.com/barada02/DL_With_Pytorch\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n","✅ Environment Ready!\n"]}],"source":["# Using Drive as storage and github for version controll.\n","\n","from google.colab import drive, userdata\n","import os\n","\n","# 1. Mount Drive\n","drive.mount('/content/drive')\n","\n","# 2. Setup Paths (Change to your actual repo name)\n","REPO_PATH = \"/content/drive/MyDrive/ML/DL_With_Pytorch\"\n","%cd {REPO_PATH}\n","\n","# 3. Secure Auth\n","token = userdata.get('GH_TOKEN')\n","username = \"barada02\"\n","repo = \"DL_With_Pytorch\"\n","!git remote set-url origin https://{token}@github.com/{username}/{repo}.git\n","\n","# 4. Identity\n","!git config --global user.email \"Chandanbarada2@gmail.com\"\n","!git config --global user.name \"Kumar\"\n","\n","!git pull origin main\n","print(\"✅ Environment Ready!\")"]},{"cell_type":"code","source":["# Push notebook changes to GitHub\n","# IMPORTANT: Press Ctrl+S (Save) before running this!\n","!git add .\n","!git commit -m \"Squeeze and Unsqueeze ex\"\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUILGGWfrue1","executionInfo":{"status":"ok","timestamp":1768414381172,"user_tz":-330,"elapsed":2108,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"9c0a297e-ecee-4d92-e8f9-3342accfd163"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 1d51dc4] Squeeze and Unsqueeze ex\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite 01_Tensor_03_Shapes.ipynb (71%)\n","Enumerating objects: 5, done.\n","Counting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (3/3), done.\n","Writing objects: 100% (3/3), 333 bytes | 41.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/barada02/DL_With_Pytorch.git\n","   e8c6a07..1d51dc4  main -> main\n"]}]},{"cell_type":"markdown","source":["# Tensor Shapes"],"metadata":{"id":"K8Bc8ihwr_XQ"}},{"cell_type":"markdown","source":["Manipulating tensor shapes is the bread and butter of deep learning. In PyTorch, these operations allow you to reorganize data to fit the expected input of different layers (like moving from a Convolutional layer to a Linear one)"],"metadata":{"id":"hp-rNi11r_UC"}},{"cell_type":"code","source":["import torch\n","torch.__version__\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"QpCvVfcNs0M9","executionInfo":{"status":"ok","timestamp":1768414219665,"user_tz":-330,"elapsed":109,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"6b9b0fb8-f1d8-4b65-9cf1-e7cfbd4461cb"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.9.0+cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# The flatten\n","### Reshape and view"],"metadata":{"id":"ue7mjZqEscTQ"}},{"cell_type":"markdown","source":["Both change the dimensions of a tensor without changing its data, but they handle memory differently.\n","\n","* view(): The OG method. It is very fast because it creates a \"view\" of the original data without copying it. Requirement: The tensor must be contiguous in memory. If you’ve just transposed a tensor, view() might throw an error.\n","\n","* reshape(): The more robust sibling. It tries to return a view if possible, but if the data isn't contiguous, it will silently copy the data to a new memory block.\n","\n","Pro Tip: Use -1 as a dimension to let PyTorch automatically calculate the size for that slot based on the remaining dimensions."],"metadata":{"id":"2UwCZyUrsiA9"}},{"cell_type":"code","source":["\n","\n","# A batch of 4 images, 3 color channels, 28x28 pixels\n","x = torch.randn(4, 3, 28, 28)\n","print(f\"Original shape: {x.shape}\")\n","\n","# Use -1 to say: \"Keep the batch size (4), but squash everything else\"\n","flattened = x.view(4, -1)\n","print(f\"Flattened shape: {flattened.shape}\") # [4, 2352]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pl5b-fIUsMns","executionInfo":{"status":"ok","timestamp":1768414237359,"user_tz":-330,"elapsed":119,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"c12f6507-ea90-4281-8e9a-af0e4a9fe9e4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Original shape: torch.Size([4, 3, 28, 28])\n","Flattened shape: torch.Size([4, 2352])\n"]}]},{"cell_type":"markdown","source":["# Squeeze and Unsqueeze\n","These are used to add or remove \"singleton\" dimensions (dimensions of size 1).\n","\n","* unsqueeze(dim): Adds a dimension of size 1 at the specified index.\n","\n","  * Example: Changing a shape from [3, 224, 224] to [1, 3, 224, 224] to add a \"batch\" dimension.\n","\n","* squeeze(dim): Removes a dimension of size 1. If no dimension is specified, it removes all dimensions of size 1.\n","\n","   * Example: Changing [1, 10] to [10]."],"metadata":{"id":"6tQ6A6yGtEHj"}},{"cell_type":"code","source":["# A single RGB image\n","img = torch.randn(3, 224, 224)\n","print(f\"Single image: {img.shape}\")\n","\n","# Add a batch dimension at index 0\n","batch_img = img.unsqueeze(0)\n","print(f\"After unsqueeze(0): {batch_img.shape}\") # [1, 3, 224, 224]\n","\n","# Remove it back\n","back_to_img = batch_img.squeeze(0)\n","print(f\"After squeeze(0): {back_to_img.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I25dRazhtZi8","executionInfo":{"status":"ok","timestamp":1768414361625,"user_tz":-330,"elapsed":85,"user":{"displayName":"Chandan Kumar Barada","userId":"01468100662972031370"}},"outputId":"389c9d6c-194f-43a9-851b-3bc1dd31223d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Single image: torch.Size([3, 224, 224])\n","After unsqueeze(0): torch.Size([1, 3, 224, 224])\n","After squeeze(0): torch.Size([3, 224, 224])\n"]}]}]}